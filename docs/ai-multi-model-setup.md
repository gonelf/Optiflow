# Multi-Model AI System Setup Guide

Reoptimize uses a multi-model AI system with automatic fallback between different AI providers. This ensures high availability and cost optimization by prioritizing free-tier services.

## Supported AI Providers

### 1. Google Gemini Flash (Priority 1 - Recommended)
- **Model**: `gemini-1.5-flash`
- **Free Tier**: ✅ 15 requests/minute, 1 million tokens/day
- **Cost**: Free up to quota, then $0.075/1M input tokens
- **Speed**: Fast (optimized for speed)
- **Best For**: Most use cases, high-volume usage

### 2. OpenAI GPT-4 (Priority 2 - Fallback)
- **Model**: `gpt-4-turbo-preview`
- **Free Tier**: ❌ No free tier
- **Cost**: $10/1M input tokens, $30/1M output tokens
- **Speed**: Moderate
- **Best For**: Fallback when Gemini quota is exhausted

## How Fallback Works

The system automatically tries AI providers in order of priority:

```
1. Attempt with Gemini Flash (free tier)
   ↓ (if rate limit or error)
2. Fallback to OpenAI GPT-4
   ↓ (if both fail)
3. Return error to user
```

**Rate Limit Detection**: The system detects these errors and triggers fallback:
- "rate limit"
- "quota exceeded"
- "too many requests"
- "resource exhausted"
- HTTP 429 status

## Environment Variables Setup

### Recommended Configuration (Both Services)

```bash
# Google Gemini (Priority 1 - Free Tier)
GEMINI_API_KEY=your_gemini_api_key_here

# OpenAI (Priority 2 - Paid Fallback)
OPENAI_API_KEY=sk-your_openai_key_here
```

### Minimum Configuration (Gemini Only - Free)

```bash
# Only Gemini (no fallback)
GEMINI_API_KEY=your_gemini_api_key_here
```

### Alternative Configuration (OpenAI Only)

```bash
# Only OpenAI (paid, no fallback)
OPENAI_API_KEY=sk-your_openai_key_here
```

## Getting API Keys

### Google Gemini API Key (Free)

1. Go to [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Click "Create API Key"
3. Copy the key and add to `.env`:
   ```bash
   GEMINI_API_KEY=AIzaSy...
   ```

**Free Tier Limits**:
- 15 requests per minute
- 1 million tokens per day
- No credit card required

### OpenAI API Key (Paid)

1. Go to [OpenAI Platform](https://platform.openai.com/api-keys)
2. Create an account and add billing information
3. Click "Create new secret key"
4. Copy the key and add to `.env`:
   ```bash
   OPENAI_API_KEY=sk-proj-...
   ```

**Note**: OpenAI requires payment method on file.

## Checking Service Status

### Via API

```bash
curl -X GET http://localhost:3000/api/ai/status \
  -H "Authorization: Bearer YOUR_SESSION_TOKEN"
```

Response:
```json
{
  "configured": {
    "gemini": true,
    "openai": true
  },
  "status": {
    "available": ["gemini", "openai"],
    "failed": []
  },
  "recentFallbacks": [
    {
      "provider": "gemini",
      "timestamp": "2026-01-23T10:30:00Z",
      "error": "rate limit exceeded"
    }
  ],
  "recommendation": "All configured AI services are healthy!"
}
```

### Via Code

```typescript
import { AIGeneratorService } from '@/services/ai/generator.service';

// Check service status
const status = await AIGeneratorService.getServiceStatus();
console.log('Available:', status.available);
console.log('Failed:', status.failed);

// Get fallback history
const history = AIGeneratorService.getFallbackHistory();
console.log('Recent fallbacks:', history);
```

## Usage Examples

### Generate a Page (Automatic Fallback)

```typescript
import { AIGeneratorService } from '@/services/ai/generator.service';

const page = await AIGeneratorService.generatePage({
  description: 'A landing page for a SaaS product',
  industry: 'Software',
  targetAudience: 'Small businesses',
  pageType: 'landing',
});

console.log('Generated by:', page.generatedBy); // "gemini" or "openai"
```

The system will:
1. Try Gemini first (free tier)
2. If Gemini fails or hits rate limit, try OpenAI
3. Return the result with metadata about which provider was used

### Generate with Streaming

```typescript
const result = await AIGeneratorService.generatePageStreaming(
  input,
  (chunk) => {
    console.log('Chunk:', chunk);
  }
);

console.log('Used provider:', result.provider);
```

## Cost Optimization Strategies

### Strategy 1: Free Tier Only (Recommended for Development)

```bash
# Only use Gemini (free tier)
GEMINI_API_KEY=your_key
# No OPENAI_API_KEY
```

**Pros**:
- 100% free up to quota
- 1 million tokens/day is generous

**Cons**:
- No fallback if quota exceeded
- Rate limited to 15 requests/minute

### Strategy 2: Gemini + OpenAI Fallback (Recommended for Production)

```bash
GEMINI_API_KEY=your_gemini_key
OPENAI_API_KEY=your_openai_key
```

**Pros**:
- Cost-efficient (uses free tier first)
- High availability with fallback
- Automatic switching

**Cons**:
- Requires OpenAI billing
- Small cost when Gemini quota exceeded

### Strategy 3: OpenAI Only

```bash
OPENAI_API_KEY=your_openai_key
```

**Pros**:
- Consistent model quality
- No rate limit concerns

**Cons**:
- Higher costs ($10-30/million tokens)
- No free tier

## Monitoring & Debugging

### View Fallback History

```typescript
// Get last 10 fallback events
const history = AIGeneratorService.getFallbackHistory();

history.forEach(event => {
  console.log(`${event.provider} failed at ${event.timestamp}`);
  console.log(`Error: ${event.error}`);
});
```

### Console Logs

The system logs fallback attempts:

```
Attempting generation with gemini...
✗ gemini failed: rate limit exceeded
Rate limit hit for gemini, trying next provider...
Attempting generation with openai...
✓ Successfully generated with openai
```

## Rate Limit Management

### Gemini Rate Limits
- **Per Minute**: 15 requests
- **Per Day**: 1 million tokens (~500-1000 page generations)

**Recommendations**:
- Implement request queuing for high traffic
- Cache common generations
- Use batch processing during off-peak hours

### OpenAI Rate Limits
- **Tier 1**: 500 requests/minute
- **Tier 2+**: Higher limits with billing

## Troubleshooting

### Problem: "No AI services configured"

**Solution**: Add at least one API key to `.env`:
```bash
GEMINI_API_KEY=your_key
# or
OPENAI_API_KEY=your_key
```

### Problem: "All AI providers failed"

**Possible Causes**:
1. All services hit rate limits
2. Invalid API keys
3. Network connectivity issues

**Solutions**:
1. Wait for rate limits to reset (1 minute for Gemini)
2. Verify API keys are valid
3. Check `/api/ai/status` endpoint
4. Add additional provider as fallback

### Problem: High OpenAI costs

**Solutions**:
1. Ensure Gemini is configured and working
2. Check fallback history to see why Gemini is failing
3. Increase Gemini quota or implement request queuing
4. Cache frequently generated content

### Problem: Slow response times

**Causes**:
- Fallback adds latency (trying multiple providers)
- Network latency to AI services

**Solutions**:
1. Ensure primary provider (Gemini) is healthy
2. Use streaming for better UX
3. Implement response caching
4. Pre-generate common pages

## Best Practices

### 1. Configure Both Services

Always configure both Gemini and OpenAI for maximum reliability:

```bash
GEMINI_API_KEY=...  # Free tier, try first
OPENAI_API_KEY=...  # Paid fallback
```

### 2. Monitor Fallback Rate

```typescript
// Alert if fallback rate > 10%
const history = AIGeneratorService.getFallbackHistory();
const recentFallbacks = history.filter(
  f => f.timestamp > new Date(Date.now() - 3600000)
);

if (recentFallbacks.length > 10) {
  console.warn('High fallback rate detected!');
}
```

### 3. Implement Caching

```typescript
// Cache generated pages to reduce API calls
const cacheKey = `page_${description}`;
const cached = await cache.get(cacheKey);

if (cached) {
  return cached;
}

const page = await AIGeneratorService.generatePage(input);
await cache.set(cacheKey, page, { ttl: 3600 });
```

### 4. Use Streaming for Better UX

```typescript
// Show progress to users
await AIGeneratorService.generatePageStreaming(
  input,
  (chunk) => {
    updateUI(chunk); // Show incremental progress
  }
);
```

## Performance Metrics

### Response Times

| Provider | Average | P95 | P99 |
|----------|---------|-----|-----|
| Gemini Flash | 2-4s | 6s | 8s |
| OpenAI GPT-4 | 3-8s | 12s | 15s |

### Cost Comparison (1000 Generations)

| Provider | Input Tokens | Output Tokens | Cost |
|----------|--------------|---------------|------|
| Gemini | 500K | 1M | $0 (free tier) |
| OpenAI | 500K | 1M | $35 |

**Savings with fallback**: ~$30-35 per 1000 generations

## Advanced Configuration

### Custom Provider Priority

```typescript
import { MultiModelService } from '@/services/ai/multi-model.service';

// Custom configuration
const service = new MultiModelService([
  {
    provider: 'gemini',
    model: 'gemini-1.5-flash',
    priority: 1,
  },
  {
    provider: 'openai',
    model: 'gpt-4-turbo-preview',
    priority: 2,
  },
]);
```

### Health Checks

```typescript
// Check if Gemini is healthy before using
const isHealthy = await service.checkProviderHealth('gemini');

if (!isHealthy) {
  console.warn('Gemini is down, will use OpenAI');
}
```

## Support

For issues with:
- **Gemini API**: [Google AI Support](https://developers.googleblog.com/google-ai)
- **OpenAI API**: [OpenAI Help Center](https://help.openai.com/)
- **Reoptimize System**: Check application logs and `/api/ai/status`

## Summary

✅ **Free Tier First**: Gemini provides generous free quota
✅ **Automatic Fallback**: No manual intervention needed
✅ **Cost Optimized**: Uses free tier before paid services
✅ **High Availability**: Multiple providers ensure uptime
✅ **Easy Setup**: Just add environment variables

**Recommended Setup for Production**:
```bash
GEMINI_API_KEY=your_gemini_key    # Primary (free)
OPENAI_API_KEY=your_openai_key    # Fallback (paid)
```
